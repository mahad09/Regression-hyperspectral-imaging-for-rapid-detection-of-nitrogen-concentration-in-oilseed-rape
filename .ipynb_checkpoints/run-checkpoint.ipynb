{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "welcome-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score, mean_squared_error, r2_score, roc_auc_score, plot_roc_curve, RocCurveDisplay\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pdb\n",
    "import seaborn as sns\n",
    "from yellowbrick.regressor import PredictionError\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_FOREST_REGRESSOR_FILENAME = 'random_forest_regressor.sav'\n",
    "DECISION_TREE_REGRESSOR_FILENAME = 'decision_tree_regressor.sav'\n",
    "SUPPORT_VECTOR_MACHINE_FILENAME = 'svm_regressor.sav'\n",
    "file_path = 'Meanspectra.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "  df = pd.read_csv(file_path)\n",
    "\n",
    "  profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)\n",
    "    \n",
    "  profile.to_file(output_file=\"dataset_report.html\")\n",
    "  profile.to_file(output_file=\"dataset_report.json\")\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_splitting(df):\n",
    "  x_train = df.loc[df['Dataset']==1].iloc[:, df.columns!='N Values'].values\n",
    "  x_test = df.loc[df['Dataset']==0].iloc[:, df.columns!='N Values'].values\n",
    "\n",
    "  y_train = df.loc[df['Dataset']==1]['N Values'].values\n",
    "  y_test = df.loc[df['Dataset']==0]['N Values'].values\n",
    "\n",
    "  return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(x_train, y_train, x_test):\n",
    "  # selecting the best k number of features by change k parameter.\n",
    "  fs = SelectKBest(score_func=f_regression, k=350)\n",
    "  fs.fit(x_train, y_train)\n",
    "\n",
    "  x_train_fs = fs.transform(x_train)\n",
    "  x_test_fs = fs.transform(x_test)\n",
    "\n",
    "  # for i in range(len(fs.scores_)):\n",
    "  #   print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "\n",
    "  # uncomment the lines to plot the scores of each feature\n",
    "  # plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "  # plt.show()\n",
    "\n",
    "  return x_train_fs, x_test_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_regressor(x_train, y_train):\n",
    "  regressor = DecisionTreeRegressor(max_depth=10, random_state=0)\n",
    "\n",
    "  print('Decision tree regressor Information:')\n",
    "  print(regressor.get_params())\n",
    "\n",
    "  regressor.fit(x_train, y_train)\n",
    "\n",
    "  # pickle.dump(regressor, open(DECISION_TREE_REGRESSOR_FILENAME, 'wb'))\n",
    "\n",
    "  return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor(x_train, y_train):\n",
    "  regressor = RandomForestRegressor(max_depth=20, verbose=1, n_jobs=-1)\n",
    "\n",
    "  print('Random forest regressor Information:')\n",
    "  print(regressor.get_params())\n",
    "\n",
    "  regressor.fit(x_train, y_train)\n",
    "\n",
    "  # pickle.dump(regressor, open(RANDOM_FOREST_REGRESSOR_FILENAME, 'wb'))\n",
    "\n",
    "  return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine_regressor(x_train, y_train):\n",
    "  regressor = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2, max_iter=50000, verbose=True))\n",
    "\n",
    "  print('SVM Information:')\n",
    "  print(regressor.get_params())\n",
    "\n",
    "  regressor.fit(x_train, y_train)\n",
    "\n",
    "  # pickle.dump(regressor, open(SUPPORT_VECTOR_MACHINE_FILENAME, 'wb'))\n",
    "\n",
    "  return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(x_test, y_test, regressor):\n",
    "  # regressor = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "  y_predict = regressor.predict(x_test)\n",
    "\n",
    "  accuracy = regressor.score(x_test, y_test)\n",
    "  print('Accuracy: ', accuracy*100)\n",
    "\n",
    "  variance_score = explained_variance_score(y_test, y_predict)\n",
    "  print('Explained variance score: ', variance_score)\n",
    "\n",
    "  r2_accuracy = r2_score(y_test, y_predict)\n",
    "  print('r2 score: ', r2_accuracy)\n",
    "\n",
    "  mae = mean_absolute_error(y_test, y_predict)\n",
    "  print('Mean absolute error: %.3f' % mae)\n",
    "\n",
    "  mse = mean_squared_error(y_test, y_predict)\n",
    "  print('Mean squared error: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_error(x_test, y_test, regressor):\n",
    "  visualizer = PredictionError(regressor)\n",
    "  visualizer.score(x_test, y_test)\n",
    "  visualizer.show(outpath=visualizer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset()\n",
    "x_train, y_train, x_test, y_test = dataset_splitting(df)\n",
    "x_train, x_test = feature_selection(x_train, y_train, x_test)\n",
    "# model = decision_tree_regressor(x_train, y_train)\n",
    "model = random_forest_regressor(x_train, y_train)\n",
    "# model = support_vector_machine_regressor(x_train, y_train)\n",
    "model_evaluation(x_test, y_test, model)\n",
    "plot_prediction_error(x_test, y_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
